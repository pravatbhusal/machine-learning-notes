{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Networks (ANNs)\n",
    "The fundamental neural network to deep learning. We will create a simple ANN using Keras in this lecture, but first let's learn about the essential mechanisms of an artificial neural network.\n",
    "\n",
    "### Non-Neural Network Learning\n",
    "When not using a neural network, then you just using a bunch of if statements to check if certain conditions are true then it helps determine a predicted value.\n",
    "\n",
    "For instance, classifying an animal as a dog or cat. We would use if statements to check if the animal's ears are pointy or lopped, snout is small or large, etc.\n",
    "\n",
    "### Neural Network Learning\n",
    "When using a neural network, you program the network's architecture then it'll determine the necessary characteristics itself.\n",
    "\n",
    "For instance, the neural network would learn the difference between a dog or cat and use what it learned to predict whether or not an animal is a dog or cat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuron (Node)\n",
    "A Node that transmits data through layers.\n",
    "\n",
    "<img src=\"images/ann/neuron.png\" height=\"65%\" width=\"65%\"></img>\n",
    "- The input values are standarized (and sometimes normalized)\n",
    "- The output value can be continuous (number), binary (yes or no), or categorical (dummy variables)\n",
    "\n",
    "The inputs are transmitted through neuron(s), which are processed to determine an output value.\n",
    "\n",
    "In real life, the input values of a human are the 5 senses: sight, touch, sound, taste, and smell. And these input values are transmitted to the neurons, which the neurons will process and determine an output.\n",
    "\n",
    "For example, if I touch a fire with my hand, then my touch input value will signal the neuron, and then the neuron will process it and determine that I need to take my hand away from the fire.\n",
    "\n",
    "### Weights\n",
    "For each synapse (signal), there can be weights to measure the significance of a signal. Weights are crucial, and they're the values that get adjusted across the neural network. This is where gradient descent and backpropagation come into play, but we'll get to that later.\n",
    "\n",
    "<img src=\"images/ann/weights_neuron.png\" height=\"75%\" width=\"75%\"></img>\n",
    "- W1, W2, and Wm are the individual weights for each synapse (arrow, or signal)\n",
    "\n",
    "The mathematics inside the neuron is a value that determines whether or not to pass the signal to the next neuron in the next layer. This value is determined through an activation function that is applied on the weighted sum of the input values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation Function\n",
    "Adds a bias on the weighted sum of the independent values. There are many types of activation functions, and some work better than others depending on the neural network.\n",
    "\n",
    "Note that the input values must be featured scaled (standarized or normalized) for these functions to work properly.\n",
    "\n",
    "Below are different types of activation functions.\n",
    "- The x-value is the weighted sum of the input value(s)\n",
    "- The y-value is the neuron's contribution to the output value(s)\n",
    "\n",
    "### 1. Threshold Function\n",
    "A \"binary\" (yes or no) activation function.\n",
    "\n",
    "<img src=\"images/ann/threshold_function.png\" height=\"50%\" width=\"50%\"></img>\n",
    "\n",
    "### 2. Sigmoid Function\n",
    "A smooth activation function with gradual progression, very useful for the output layer to predict the probability of success.\n",
    "\n",
    "<img src=\"images/ann/sigmoid_function.png\" height=\"50%\" width=\"50%\"></img>\n",
    "\n",
    "### 3. Rectifier Function\n",
    "One of the most popular functions, a linear curve that increases after the x-value of 0.\n",
    "\n",
    "<img src=\"images/ann/rectifier_function.png\" height=\"50%\" width=\"50%\"></img>\n",
    "\n",
    "### 4. Hyperbolic Tangent (tanh)\n",
    "Similar to the sigmoid function, but the function's value can be a negative.\n",
    "\n",
    "<img src=\"images/ann/tanh_function.png\" height=\"50%\" width=\"50%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Do Neural Networks Work?\n",
    "Let's learn how neural networks actually work.\n",
    "\n",
    "### Shallow Neural Network\n",
    "In machine learning algorithms without deep learning, the algorithm can be modelled below.\n",
    "\n",
    "<img src=\"images/ann/basic_neural_network.png\" height=\"50%\" width=\"50%\"></img>\n",
    "\n",
    "This neural network is very basic: there are only independent variables (input layer), parameter tuning variables (weights), and a dependent variable (output layer). This is actually how most machine learning models work if there is no deep learning involved.\n",
    "\n",
    "Fortunately, in deep learning, there are \"hidden\" layers that increase the accuracy of the model.\n",
    "\n",
    "### Deep Neural Network\n",
    "A deep neural network has \"hidden\" layers that process the input values further. Let's assume a neural network has already been trained, so let's observe how it will work.\n",
    "\n",
    "The neural network below is trying to predict the price of a house based on area, bedrooms, distance to city, and age.\n",
    "\n",
    "<img src=\"images/ann/neural_network_house_price.png\" height=\"50%\" width=\"50%\"></img>\n",
    "\n",
    "Each neuron in the hidden layer only accepts only some input values because of the weights from the synapses (signals) to calculate whether or not a signal is significant enough for the neuron.\n",
    "\n",
    "For example, the middle neuron in the hidden layer focuses on only the \"Area\", \"Bedrooms\", and \"Age\" input values. Maybe because the already trained neuron determined that younger people prefer high area and lots of bedrooms, so it only accepts the signals from those input values to determine if the criterions are met.\n",
    "\n",
    "Another example is the last neuron in the hidden layer that focuses on only the \"Age\". Maybe because the neuron determined that a house older than 100+ years is priced significantly higher due to historical reasons. This is a good example of when to use the rectifier activiation function because the neuron would check if the age is 100+ then the neuron's contribution to the output increases and if not then the neuron's contribution to the output is 0.\n",
    "\n",
    "Together, all the neurons can be used to predict the price of a house as seen in the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Propagations\n",
    "There are two types of propagations: front and back propagation. These propagations are necessary in order for the neural network to learn the trends of the data set.\n",
    "\n",
    "Let's say we're trying to determine a person's exam score based on hos or her study hours, sleep hours, and quiz score. \n",
    "\n",
    "### Forward Propagation\n",
    "<img src=\"images/ann/forward_propagation.png\" height=\"50%\" width=\"50%\"></img>\n",
    "- The output (predicted) exam score is noted as y^ and the actual exam score is noted as y\n",
    "\n",
    "In forward propagation, the neural network predicts an output (predicted) value. The neural network uses a cost function (C) to compare the output to the actual value.\n",
    "\n",
    "### Back Propagation\n",
    "<img src=\"images/ann/back_propagation.png\" height=\"50%\" width=\"50%\"></img>\n",
    "\n",
    "Then using the cost function, the network signals a back propagation to update the weights of the synapses.\n",
    "\n",
    "### Epoch\n",
    "An epoch is when a forward and back propagation occurs in a neural network. The goal is to minimize the cost function, so we must perform multiple epochs to better learn the trends of the data set.\n",
    "\n",
    "However, too many epochs may cause overfitting of the data set. It means that your model does not learn the data, it memorizes the data. To avoid overfitting, early stop the model once the validation accuracy flattens out, or it starts decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
